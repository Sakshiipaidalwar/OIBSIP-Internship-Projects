{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOecOSLXnMmKpiqYXJMPojT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sakshiipaidalwar/OIBSIP-Internship-Projects/blob/main/Sentiment_Analysis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SENTIMENT ANALYSIS"
      ],
      "metadata": {
        "id": "Vkz2DllW18W6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary goal is to develop a sentiment analysis model that can accurately classify the\n",
        "sentiment of text data, providing valuable insights into public opinion, customer feedback, and\n",
        "social media trends."
      ],
      "metadata": {
        "id": "lLZOrPyi16oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "COT401UtuY0L"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Twitter Sentiment Dataset\n",
        "df = pd.read_csv('/content/Sentiment Dataset.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFCQteLIugRh",
        "outputId": "8eac6402-5c4c-4e3c-9ee6-63e6bdd23726"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          clean_text  category\n",
            "0  when modi promised “minimum government maximum...      -1.0\n",
            "1  talk all the nonsense and continue all the dra...       0.0\n",
            "2  what did just say vote for modi  welcome bjp t...       1.0\n",
            "3  asking his supporters prefix chowkidar their n...       1.0\n",
            "4  answer who among these the most powerful world...       1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_tweet(tweet):\n",
        "    # Ensure tweet is a string\n",
        "    tweet = str(tweet) if not pd.isna(tweet) else \"\"\n",
        "    # Remove URLs\n",
        "    tweet = re.sub(r'http\\S+', '', tweet)\n",
        "    # Remove mentions\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)\n",
        "    # Remove hashtags (optional, keep if needed for sentiment analysis, otherwise remove)\n",
        "    tweet = re.sub(r'#\\w+', '', tweet)\n",
        "    # Remove digits\n",
        "    tweet = re.sub(r'\\d+', '', tweet)\n",
        "    # Remove non-word characters and extra spaces\n",
        "    tweet = re.sub(r'\\W+', ' ', tweet)\n",
        "    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
        "    return tweet\n",
        "    # Apply preprocessing\n",
        "df['cleaned_text'] = df['clean_text'].apply(preprocess_tweet)\n",
        "df['cleaned_text'].fillna(\"missing\", inplace=True)\n",
        "\n",
        "# Handling missing values in the 'category' column\n",
        "df.dropna(subset=['category'], inplace=True)\n",
        "df['category'] = df['category'].astype(int)\n",
        "\n",
        "print(df[['cleaned_text', 'category']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0cCr0EBugXg",
        "outputId": "37c1e759-6756-4b3c-edb1-485598efb1f8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        cleaned_text  category\n",
            "0  when modi promised minimum government maximum ...        -1\n",
            "1  talk all the nonsense and continue all the dra...         0\n",
            "2  what did just say vote for modi welcome bjp to...         1\n",
            "3  asking his supporters prefix chowkidar their n...         1\n",
            "4  answer who among these the most powerful world...         1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['category'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "pkPkofalvDNI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count Vectorizer\n",
        "cvectorizer = CountVectorizer()\n",
        "X_train_vectorized = cvectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = cvectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "EArQgKbsvDPx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multinomial Naive Bayes Classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_vectorized, y_train)\n",
        "y_pred = nb_classifier.predict(X_test_vectorized)"
      ],
      "metadata": {
        "id": "myi_0vluvDSj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results\n",
        "print(\"Classification Report (ML-based):\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy Score (ML-based):\")\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTJE9yOXvDWH",
        "outputId": "abfa9d6e-22a3-443f-c66c-7e69f7cf6d6f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (ML-based):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.75      0.62      0.68      7230\n",
            "           0       0.91      0.62      0.74     10961\n",
            "           1       0.69      0.92      0.79     14404\n",
            "\n",
            "    accuracy                           0.75     32595\n",
            "   macro avg       0.78      0.72      0.74     32595\n",
            "weighted avg       0.78      0.75      0.75     32595\n",
            "\n",
            "Accuracy Score (ML-based):\n",
            "0.7525387329344991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count Vectorizer with N-grams\n",
        "cvectorizer = CountVectorizer(ngram_range=(1, 4))\n",
        "X_train_vectorized = cvectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = cvectorizer.transform(X_test)\n",
        "nb_classifier.fit(X_train_vectorized, y_train)\n",
        "y_pred = nb_classifier.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Classification Report (ML-based with n-grams):\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy Score (ML-based with n-grams):\")\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyMLeNNwvWLc",
        "outputId": "39135109-9eb8-4d94-e73d-97982ddfb63f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (ML-based with n-grams):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.87      0.23      0.36      7230\n",
            "           0       0.90      0.29      0.44     10961\n",
            "           1       0.52      0.98      0.68     14404\n",
            "\n",
            "    accuracy                           0.58     32595\n",
            "   macro avg       0.76      0.50      0.49     32595\n",
            "weighted avg       0.73      0.58      0.53     32595\n",
            "\n",
            "Accuracy Score (ML-based with n-grams):\n",
            "0.5801810093572634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Vectorizer with Trigrams\n",
        "vectorizertf = TfidfVectorizer(ngram_range=(1, 3), max_features=5000)\n",
        "X_train_vectorized = vectorizertf.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizertf.transform(X_test)\n",
        "nb_classifier = MultinomialNB(alpha=0.1)\n",
        "nb_classifier.fit(X_train_vectorized, y_train)\n",
        "y_pred = nb_classifier.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Classification Report (ML-based with TF-IDF and trigrams):\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy Score (ML-based with TF-IDF and trigrams):\")\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWe385-Yv4dY",
        "outputId": "77d698ae-b5db-4239-e6fc-c0d59a68a946"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (ML-based with TF-IDF and trigrams):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.85      0.47      0.61      7230\n",
            "           0       0.85      0.72      0.78     10961\n",
            "           1       0.69      0.92      0.79     14404\n",
            "\n",
            "    accuracy                           0.75     32595\n",
            "   macro avg       0.80      0.70      0.72     32595\n",
            "weighted avg       0.78      0.75      0.74     32595\n",
            "\n",
            "Accuracy Score (ML-based with TF-IDF and trigrams):\n",
            "0.7531830035281485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing the text\n",
        "cvectorizer = CountVectorizer()\n",
        "X = cvectorizer.fit_transform(df['cleaned_text'])\n",
        "y = df['category']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training a Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting and evaluating the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCtBf3pyv4gJ",
        "outputId": "b0e4a098-f715-4586-90cd-cc80f5b01118"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.73      0.63      0.68      7230\n",
            "           0       0.91      0.63      0.74     10961\n",
            "           1       0.70      0.90      0.79     14404\n",
            "\n",
            "    accuracy                           0.75     32595\n",
            "   macro avg       0.78      0.72      0.74     32595\n",
            "weighted avg       0.77      0.75      0.75     32595\n",
            "\n",
            "Accuracy: 0.7514649486117503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR=LogisticRegression()\n",
        "LR.fit(X_train_vectorized, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "SEPDUlLov4i7",
        "outputId": "537b317c-a10f-4be5-9b42-7760d0314b4f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR_pred = LR.predict(X_test_vectorized)"
      ],
      "metadata": {
        "id": "qxOYKrUlv4mV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report (Logistic regression):\")\n",
        "print(classification_report(y_test, LR_pred))\n",
        "print(\"Accuracy Score (Logistic regression):\")\n",
        "print(accuracy_score(y_test, LR_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcGcOR_dy2s5",
        "outputId": "48279797-ae2b-4c1b-e541-05d447be3482"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Logistic regression):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.90      0.79      0.84      7230\n",
            "           0       0.89      0.97      0.93     10961\n",
            "           1       0.93      0.92      0.92     14404\n",
            "\n",
            "    accuracy                           0.91     32595\n",
            "   macro avg       0.91      0.89      0.90     32595\n",
            "weighted avg       0.91      0.91      0.91     32595\n",
            "\n",
            "Accuracy Score (Logistic regression):\n",
            "0.9075625095873601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New Cell for Tweet Sentiment Analysis\n",
        "def analyze_tweet_sentiment(tweet, model, vectorizertf):\n",
        "\n",
        "    tweet_vectorized = vectorizertf.transform([tweet])\n",
        "    sentiment = model.predict(tweet_vectorized)[0]\n",
        "\n",
        "    if sentiment == 1:\n",
        "        return \"The sentiment for the previous tweet is positive.\"\n",
        "    elif sentiment == 0:\n",
        "        return \"The sentiment for the previous tweet is neutral.\"\n",
        "    else:\n",
        "        return \"The sentiment for the previous tweet is negative.\"\n",
        "\n",
        "# Example Usage\n",
        "new_tweet = input(\"Enter a tweet: \")\n",
        "print(analyze_tweet_sentiment(new_tweet, LR, vectorizertf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2PUjzIFy2vM",
        "outputId": "1ebac4e7-5a2a-4eb4-efd6-4d8ef084075c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a tweet: fabulous\n",
            "The sentiment for the previous tweet is neutral.\n"
          ]
        }
      ]
    }
  ]
}